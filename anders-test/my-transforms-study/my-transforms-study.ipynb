{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be56e845-cc2b-43e6-b007-53b49fe85f86",
   "metadata": {},
   "source": [
    "# transforms 学习\n",
    "\n",
    "https://pytorch.org/vision/stable/transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55c741f2-bde0-420b-a65f-e70dccb6a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.io import read_image\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision import datasets, models, transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf1af3e-15aa-4174-ad78-c0108720b124",
   "metadata": {},
   "source": [
    "# 图片类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523dc25d-7d7e-461b-8bbd-3ed630b17c19",
   "metadata": {},
   "source": [
    "## PIL.Image.Image\n",
    "https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab190617-3bf8-44ea-b547-8aad286f10c2",
   "metadata": {},
   "source": [
    "## PIL.ImageFile.ImageFile\n",
    "https://pillow.readthedocs.io/en/stable/reference/ImageFile.html#PIL.ImageFile.ImageFile\n",
    "\n",
    "父类为PIL.Image.Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da06299d-5c0c-4c30-890f-ceacd16bfb20",
   "metadata": {},
   "source": [
    "## PIL.JpegImagePlugin.JpegImageFile\n",
    "https://pillow.readthedocs.io/en/stable/reference/plugins.html#PIL.JpegImagePlugin.JpegImageFile\n",
    "\n",
    "父类为PIL.ImageFile.ImageFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbfbb39-ed85-48a6-be0b-974256ded5e3",
   "metadata": {},
   "source": [
    "### 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94b64bfa-f1cd-4380-a8b8-9734b8f741ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
      "<class 'PIL.Image.Image'>\n"
     ]
    }
   ],
   "source": [
    "orig_img = Image.open(Path('assets') / 'astronaut.jpg')\n",
    "# JpegImageFile是ImageFile的子类\n",
    "print(type(orig_img)) # <class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
    "img = orig_img.rotate(45)\n",
    "print(type(img))\n",
    "img.save(Path('assets') /'astronaut45.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552ece0e-608b-47e6-af86-7584a4ca313a",
   "metadata": {},
   "source": [
    "### 变为numpy数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fef25e4-afd0-4ae6-aaff-b104e431f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(img) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1f0581-5e06-425f-928e-461fd3f99ad2",
   "metadata": {},
   "source": [
    "### 变为tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07aa4f3d-e1ac-459e-b97e-646ccca3e023",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = transforms.ToTensor()\n",
    "img = tt(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5713f4-ba86-4583-87b3-a5ff4372af0f",
   "metadata": {},
   "source": [
    "# 读取图片的3种方式\n",
    "## read_image\n",
    "D:\\GitHub\\book_DeepLearning_in_PyTorch_Source\\anders-test\\vision-examples-gallery\\dogs.py\n",
    "\n",
    "这里面的代码用了这个api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02a9fc71-a1d1-413b-a4f5-fb72e9745989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([3, 500, 500])\n",
      "tensor([45, 56, 58], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# 结果为tensor, shape = [3, 500, 500]\n",
    "# 值为rgb值(0到255)\n",
    "dog1 = read_image(str(Path('assets') / 'dog1.jpg'))\n",
    "print(type(dog1)) # <class 'torch.Tensor'>\n",
    "print(dog1.shape) # torch.Size([3, 500, 500])\n",
    "# print(dog1)\n",
    "# 显示x，y坐标的rgb值\n",
    "x=2\n",
    "y=1\n",
    "print(dog1[:,x,y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94576e7-b6f8-4aed-a683-7ab518d5a7cb",
   "metadata": {},
   "source": [
    "## Image.open\n",
    "D:\\GitHub\\book_DeepLearning_in_PyTorch_Source\\anders-test\\my-transforms-study\\plot_transforms.ipynb\n",
    "\n",
    "这里面的代码用了这个api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a937ae3e-ecf2-413b-a042-d25cd87b3eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n"
     ]
    }
   ],
   "source": [
    "orig_img = Image.open(Path('assets') / 'astronaut.jpg')\n",
    "# JpegImageFile是ImageFile的子类\n",
    "print(type(orig_img)) # <class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
    "orig_img.rotate(45).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc00da5-3284-48fb-8876-5c723371d038",
   "metadata": {},
   "source": [
    "## ImageFolder\n",
    "https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html\n",
    "\n",
    "训练的代码都用了这个，使用了transforms.ToTensor()后，表示颜色的数据，都是0到1之间的小数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06e27f40-0566-4baa-964e-1e1781250bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes ['39', '620', 'aoli', 'eber', 'fengshi', 'kouzhao', 'kushen', 'lianhua', 'ningjiao', 'nut', 'shangtong', 'yikang', 'zhuangyao', 'zhuodu']\n",
      "1: <class 'PIL.Image.Image'>\n",
      "2: <class 'PIL.Image.Image'>\n",
      "3: <class 'torch.Tensor'>\n",
      "4: torch.Size([3, 600, 800])\n",
      "5: tensor([[[0.9333, 0.9333, 0.9333,  ..., 0.9961, 0.9961, 1.0000],\n",
      "         [0.9294, 0.9294, 0.9294,  ..., 0.9961, 0.9961, 1.0000],\n",
      "         [0.9098, 0.9137, 0.9176,  ..., 0.9961, 0.9961, 0.9961],\n",
      "         ...,\n",
      "         [0.2941, 0.2431, 0.2392,  ..., 0.7961, 0.8784, 0.9373],\n",
      "         [0.3882, 0.2706, 0.2706,  ..., 0.8078, 0.8863, 0.9451],\n",
      "         [0.6157, 0.5843, 0.5882,  ..., 0.8353, 0.9059, 0.9569]],\n",
      "\n",
      "        [[0.9216, 0.9216, 0.9216,  ..., 0.9922, 0.9961, 1.0000],\n",
      "         [0.9176, 0.9176, 0.9216,  ..., 0.9922, 0.9961, 1.0000],\n",
      "         [0.9020, 0.9059, 0.9098,  ..., 0.9922, 0.9922, 0.9922],\n",
      "         ...,\n",
      "         [0.3059, 0.2588, 0.2706,  ..., 0.8275, 0.9059, 0.9608],\n",
      "         [0.3922, 0.2824, 0.2941,  ..., 0.8353, 0.9098, 0.9647],\n",
      "         [0.6157, 0.5961, 0.6078,  ..., 0.8549, 0.9216, 0.9725]],\n",
      "\n",
      "        [[0.9255, 0.9255, 0.9255,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [0.9216, 0.9216, 0.9255,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [0.9059, 0.9098, 0.9137,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [0.5725, 0.4902, 0.4510,  ..., 0.8392, 0.9137, 0.9686],\n",
      "         [0.6667, 0.4824, 0.3961,  ..., 0.8510, 0.9176, 0.9686],\n",
      "         [0.8824, 0.7961, 0.7176,  ..., 0.8706, 0.9333, 0.9765]]])\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "file_dir = Path('./') \n",
    "data_path = os.path.join(file_dir, \"../pkg_iden/data\")\n",
    "def func1(img):\n",
    "    print('1:',type(img)) # <class 'PIL.Image.Image'>\n",
    "    r = transforms.Resize((600,800))\n",
    "    img = r(img)\n",
    "\n",
    "    print('2:',type(img))# <class 'PIL.Image.Image'>\n",
    "    tt = transforms.ToTensor()\n",
    "    img = tt(img)\n",
    "\n",
    "    print('3:',type(img))\n",
    "    print('4:',img.shape)\n",
    "    print('5:',img)\n",
    "    return img\n",
    "# https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html\n",
    "train_dataset = datasets.ImageFolder(os.path.join(data_path, 'train'),\n",
    "                                     func1\n",
    "                                    )\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 1, shuffle = False, num_workers=0)\n",
    "print(\"classes\",train_dataset.classes)\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "print(type(images))\n",
    "print(type(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5584baa1-e2da-4c68-a614-0d68d7cd5739",
   "metadata": {},
   "source": [
    "## plt.imshow支持的图片格式\n",
    "\n",
    "numpy数组，rgb用0-1之间的小数表示\n",
    "\n",
    "也可以是255的rgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d06073-1146-49e1-8a65-f1d9f4a544fd",
   "metadata": {},
   "source": [
    "# 常用Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc067bd-221a-4a67-8e1f-45694e216328",
   "metadata": {},
   "source": [
    "## transforms.Normalize\n",
    "\n",
    "PyTorch_A_60_Minute_Blitz中的例子用了这个，其它都没用，这个有啥用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed0b635-a672-4e3f-a8ab-13c8066e0a93",
   "metadata": {},
   "source": [
    "## transforms.Pad\n",
    "例子看这个：anders-test\\my-transforms-study\\plot_transforms.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2376d9c2-aed4-460d-aac3-5fb0d4ffcfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "加边框"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
