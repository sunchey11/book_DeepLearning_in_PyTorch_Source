{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 风格迁移的实现\n",
    "\n",
    "本文件是集智AI学园开发的“火炬上的深度学习”课程的配套源代码。我们讲解了Prisma软件实现风格迁移的实现原理\n",
    "\n",
    "在这节课中，我们将学会玩图像的风格迁移。\n",
    "\n",
    "\n",
    "\n",
    "我们需要准备两张图像，一张作为化作风格，一张作为图像内容\n",
    "\n",
    "同时，在本文件中，我们还展示了如何实用GPU来进行计算 \n",
    "\n",
    "本文件是集智学园http://campus.swarma.org 出品的“火炬上的深度学习”第IV课的配套源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入必要的包\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import copy\n",
    "\n",
    "# 是否用GPU计算，如果检测到有安装好的GPU，则利用它来计算\n",
    "use_cuda = torch.cuda.is_available()\n",
    "dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、准备输入文件\n",
    "\n",
    "我们需要准备两张同样大小的文件，一张作为风格，一张作为内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#风格图像的路径\n",
    "style = 'images/escher.jpg'\n",
    "\n",
    "#内容图像的路径\n",
    "content = 'images/portrait1.jpg'\n",
    "\n",
    "\n",
    "#风格损失所占比重\n",
    "style_weight=1000\n",
    "\n",
    "#内容损失所占比重\n",
    "content_weight=1\n",
    "\n",
    "#如果内容损失越大，则结果图像就会尽可能保持图像内容不变，否则它会尽可能让风格更靠近目标画作的风格\n",
    "\n",
    "\n",
    "#注意，这两张图片必须同样大小\n",
    "\n",
    "#希望得到的图片大小（越大越清晰，计算越慢）\n",
    "imsize = 128\n",
    "\n",
    "loader = transforms.Compose([\n",
    "    transforms.Scale(imsize),  # 将加载的图像转变为指定的大小\n",
    "    transforms.ToTensor()])  # 将图像转化为tensor\n",
    "\n",
    "\n",
    "def image_loader(image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = loader(image).clone().detach().requires_grad_(True)\n",
    "    # 为了适应卷积网络的需要，虚拟一个batch的维度\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "style_img = image_loader(style).type(dtype)\n",
    "content_img = image_loader(content).type(dtype)\n",
    "\n",
    "assert style_img.size() == content_img.size(), \\\n",
    "    \"我们需要输入相同尺寸的风格和内容图像\"\n",
    "\n",
    "\n",
    "unloader = transforms.ToPILImage()  # 将其转化为PIL图像（Python Imaging Library） \n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# 绘制图像的函数\n",
    "def imshow(tensor, title=None):\n",
    "    image = tensor.clone().cpu()  # 克隆Tensor防止改变\n",
    "    image = image.view(3, imsize, imsize)  # 删除添加的batch层本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第IV课的配套源代码\n",
    "    image = unloader(image)\n",
    "    plt.imshow(image)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001) # 停一会以便更新视图\n",
    "\n",
    "# 打印输入的两张图片看一下\n",
    "plt.figure()\n",
    "imshow(style_img.data, title='Style Image')\n",
    "\n",
    "plt.figure()\n",
    "imshow(content_img.data, title='Content Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、风格迁移网络的实现\n",
    "\n",
    "值得注意的是，风格迁移的实现并没有训练一个神经网络，而是将已训练好的卷积神经网络价格直接迁移过来\n",
    "网络的学习过程并不体现为对神经网络权重的训练，而是训练一张输入的图像，让它尽可能地靠近内容图像的内容和风格图像的风格\n",
    "\n",
    "为了实现风格迁移，我们需要在迁移网络的基础上再构建一个计算图，这样可以加速计算。构建计算图分为两部：\n",
    "\n",
    "1、加载一个训练好的CNN；\n",
    "\n",
    "2、在原网络的基础上添加计算风格损失和内容损失的新计算层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 加载已训练好的大型网络VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.vgg19(pretrained=True).features\n",
    "\n",
    "# 如果可能就用GPU计算:\n",
    "if use_cuda:\n",
    "    cnn = cnn.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 重新定义新的计算模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算内容损失的神经模块\n",
    "class ContentLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, target, weight):\n",
    "        super(ContentLoss, self).__init__()\n",
    "        # 由于网络的权重都是从target上迁移过来，所以在计算梯度的时候，需要把它和原始计算图分离\n",
    "        self.target = target.detach() * weight\n",
    "        self.weight = weight\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, input):\n",
    "        # 输入input为一个特征图\n",
    "        # 它的功能就是计算误差，误差就是当前计算的内容与target之间的均方误差\n",
    "        self.loss = self.criterion(input * self.weight, self.target)\n",
    "        self.output = input\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, retain_variables=True):\n",
    "        # 开始进行反向传播算法\n",
    "        self.loss.backward()\n",
    "        return self.loss\n",
    "    \n",
    "class StyleLoss(nn.Module):\n",
    "    \n",
    "    # 计算风格损失的神经模块\n",
    "\n",
    "    def __init__(self, target, weight):\n",
    "        super(StyleLoss, self).__init__()\n",
    "        self.target = target.detach() * weight\n",
    "        self.weight = weight\n",
    "        #self.gram = GramMatrix()\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, input):\n",
    "        # 输入input就是一个特征图\n",
    "        self.output = input.clone()\n",
    "        # 计算本图像的gram矩阵，并将它与target对比\n",
    "        input = input.cuda() if use_cuda else input\n",
    "        self_G = Gram(input)\n",
    "        self_G.mul_(self.weight)\n",
    "        # 计算损失函数，即输入特征图的gram矩阵与目标特征图的gram矩阵之间的差异\n",
    "        self.loss = self.criterion(self_G, self.target)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, retain_variables=True):\n",
    "        # 反向传播算法\n",
    "        self.loss.backward(retain_graph=True)\n",
    "        return self.loss\n",
    "    \n",
    "def Gram(input):\n",
    "    # 输入一个特征图，计算gram矩阵\n",
    "    a, b, c, d = input.size()  # a=batch size(=1)\n",
    "    # b=特征图的数量\n",
    "    # (c,d)=特征图的图像尺寸 (N=c*d)\n",
    "\n",
    "    features = input.view(a * b, c * d)  # 将特征图图像扁平化为一个向量\n",
    "\n",
    "    G = torch.mm(features, features.t())  # 计算任意两个像素之间的乘积\n",
    "\n",
    "    # 我们通过除以特征图中的像素数量来归一化特征图\n",
    "    return G.div(a * b * c * d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 希望计算的内容或者风格层 :\n",
    "content_layers = ['conv_4'] #只考虑第四个卷积层的内容\n",
    "\n",
    "\n",
    "style_layers = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
    "# 考虑第1、2、3、4、5层的风格损失\n",
    "\n",
    "\n",
    "# 定义列表存储每一个周期的计算损失\n",
    "content_losses = []\n",
    "style_losses = []\n",
    "\n",
    "model = nn.Sequential()  # 一个新的序贯网络模型\n",
    "\n",
    "# 如果有GPU就把这些计算挪到GPU上:\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# 接下来要做的操作是：循环vgg的每一层，同时构造一个全新的神经网络model\n",
    "# 这个新网络与vgg基本一样，只是多了一些新的层来计算风格损失和内容损失。\n",
    "# 将每层卷积核的数据都加载到新的网络模型model上来\n",
    "i = 1\n",
    "for layer in list(cnn):\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        name = \"conv_\" + str(i)\n",
    "        #将已加载的模块放到model这个新的神经模块中\n",
    "        model.add_module(name, layer)\n",
    "\n",
    "        if name in content_layers:\n",
    "            # 如果当前层模型在定义好的要计算内容的层:\n",
    "            target = model(content_img).clone() #将内容图像当前层的feature信息拷贝到target中\n",
    "            content_loss = ContentLoss(target, content_weight) #定义content_loss的目标函数\n",
    "            content_loss = content_loss if use_cuda else content_loss\n",
    "            model.add_module(\"content_loss_\" + str(i), content_loss) #在新网络上加content_loss层\n",
    "            content_losses.append(content_loss)\n",
    "\n",
    "        if name in style_layers:\n",
    "            # 如果当前层在指定的风格层中，进行风格层损失的计算\n",
    "            target_feature = model(style_img).clone()\n",
    "            target_feature = target_feature.cuda() if use_cuda else target_feature\n",
    "            target_feature_gram = Gram(target_feature)\n",
    "            style_loss = StyleLoss(target_feature_gram, style_weight)\n",
    "            style_loss = style_loss.cuda() if use_cuda else style_loss\n",
    "            model.add_module(\"style_loss_\" + str(i), style_loss)\n",
    "            style_losses.append(style_loss)\n",
    "\n",
    "    if isinstance(layer, nn.ReLU):\n",
    "        #如果不是卷积层，则做同样处理\n",
    "        name = \"relu_\" + str(i)\n",
    "        model.add_module(name, layer)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    if isinstance(layer, nn.MaxPool2d):\n",
    "        name = \"pool_\" + str(i)\n",
    "        model.add_module(name, layer)  # ***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、风格迁移的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 首先，我们需要现准备一张原始的图像，可以是一张噪音图或者就是内容图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 如果想从调整一张噪声图像开始，请用下面一行的代码\n",
    "input_img = torch.randn(content_img.data.size(), requires_grad = True)\n",
    "\n",
    "if use_cuda:\n",
    "    input_img = input_img.cuda()\n",
    "    content_img = content_img.cuda()\n",
    "    style_img = style_img.cuda()\n",
    "# 将选中的待调整图打印出来:\n",
    "plt.figure()\n",
    "imshow(input_img.data, title='Input Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 优化输入的图像（训练过程）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先，需要先讲输入图像变成神经网络的参数，这样我们就可以用反向传播算法来调节这个输入图像了\n",
    "input_param = nn.Parameter(input_img.data)\n",
    "\n",
    "#定义个优化器，采用LBFGS优化算法来优化（试验效果很好，它的特点是可以计算大规模数据的梯度下降）\n",
    "optimizer = optim.LBFGS([input_param])\n",
    "\n",
    "# 迭代步数\n",
    "num_steps=300\n",
    "\n",
    "\n",
    "\"\"\"运行风格迁移的主算法过程.\"\"\"\n",
    "print('正在构造风格迁移模型..')\n",
    "\n",
    "print('开始优化..')\n",
    "for i in range(num_steps):\n",
    "    #每一个训练周期\n",
    "    \n",
    "    # 限制输入图像的色彩取值范围在0-1间\n",
    "    input_param.data.clamp_(0, 1)\n",
    "    \n",
    "    # 清空梯度\n",
    "    optimizer.zero_grad()\n",
    "    # 将图像输入构造的神经网络中\n",
    "    model(input_param)\n",
    "    style_score = 0\n",
    "    content_score = 0\n",
    "    \n",
    "    # 每个损失函数层都开始反向传播算法\n",
    "    for sl in style_losses:\n",
    "        style_score += sl.backward()\n",
    "    for cl in content_losses:\n",
    "        content_score += cl.backward()\n",
    "\n",
    "    # 每隔50个周期打印一次训练数据\n",
    "    if i % 50 == 0:\n",
    "        print(\"运行 {}轮:\".format(i))\n",
    "        print('风格损失 : {:4f} 内容损失: {:4f}'.format(\n",
    "            style_score.data.item(), content_score.data.item()))\n",
    "        print()\n",
    "    def closure():\n",
    "        return style_score + content_score\n",
    "    #一步优化\n",
    "    optimizer.step(closure)\n",
    "\n",
    "# 做一些修正，防止数据超界...\n",
    "output = input_param.data.clamp_(0, 1)\n",
    "\n",
    "# 打印结果图\n",
    "plt.figure()\n",
    "imshow(output, title='Output Image')\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文件是集智学园http://campus.swarma.org 出品的“火炬上的深度学习”第IV课的配套源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
